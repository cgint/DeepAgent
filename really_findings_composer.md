# DeepAgent: Core Innovations & Really Awesome Parts

## Executive Summary

DeepAgent introduces **three groundbreaking innovations** that distinguish it from traditional agent frameworks (like ReAct, AutoGPT, etc.):

1. **Unified Agentic Reasoning** - Single coherent reasoning stream without rigid Think-Act-Observe cycles
2. **Autonomous Memory Folding** - Brain-inspired three-type memory system for long-horizon planning  
3. **Multi-LLM Specialization** - Auxiliary LLM handles meta-tasks while main model focuses on reasoning

**The core logic lives in:** `src/run_deep_agent.py` ‚Üí `generate_main_reasoning_sequence()` function (lines 387-645)

---

## üéØ Innovation #1: Unified Agentic Reasoning (The Game Changer)

### What Makes It Revolutionary

**Traditional ReAct Approach:**
```
Think ‚Üí Act ‚Üí Observe ‚Üí Think ‚Üí Act ‚Üí Observe...
```
- Forced cycles: model must alternate between thinking and acting
- Phase boundaries: reasoning and actions are separate
- No global perspective: each cycle only sees the last observation

**DeepAgent's Unified Approach:**
```
Reasoning Stream ‚Üí [autonomous action markers] ‚Üí Execute ‚Üí Continue Reasoning
                    ‚Üë_________________________________________________|
```
- **Single continuous stream**: Model reasons naturally and emits action markers when it decides action is needed
- **Autonomous control**: Model itself decides when to search tools, call tools, or fold thoughts
- **Global perspective**: Model maintains full context of entire task throughout

### Where It's Implemented

**1. Prompt Engineering** (`src/prompts/prompts_deepagent.py:20-80`)

The prompts **don't enforce** Think-Act-Observe structure. Instead, they instruct the model to autonomously emit special markers:

```python
# Key markers the model can emit:
BEGIN_TOOL_SEARCH = "<tool_search>"
END_TOOL_SEARCH = "</tool_search>"
BEGIN_TOOL_CALL = "<tool_call>"
END_TOOL_CALL = "</tool_call>"
FOLD_THOUGHT = "<fold_thought>"
```

The prompt says: "When you need a tool, write `<tool_search>query</tool_search>`. When you want to call a tool, write `<tool_call>{"name": "...", "arguments": {...}}</tool_call>`."

**No forced structure** - the model reasons naturally and emits markers when it decides action is needed.

**2. Core Reasoning Loop** (`src/run_deep_agent.py:430-613`)

```python
while not seq['finished']:
    # Check what the model autonomously decided to do
    tool_search_query = extract_between(response, BEGIN_TOOL_SEARCH, END_TOOL_SEARCH)
    tool_call_query = extract_between(response, BEGIN_TOOL_CALL, END_TOOL_CALL)
    
    # Execute what model decided, then continue reasoning
    if tool_search_query:
        # Execute tool search, feed results back
        append_text = f"\n\n{BEGIN_TOOL_SEARCH_RESULT}{results}{END_TOOL_SEARCH_RESULT}\n\n"
        seq['prompt'] += append_text
    
    elif tool_call_query:
        # Execute tool call, feed response back
        tool_response = await tool_manager.call_tool(...)
        append_text = f"\n\n{BEGIN_TOOL_RESPONSE}{tool_response}{END_TOOL_RESPONSE}\n\n"
        seq['prompt'] += append_text
    
    # Continue reasoning (completion mode, not chat mode)
    response = await generate_response(
        prompt=seq['prompt'],
        stop=[END_TOOL_SEARCH, END_TOOL_CALL, FOLD_THOUGHT],  # Model generates until it decides to act
        generate_mode="completion"  # Continuation, not new turn
    )
```

**Key Insight:** The loop doesn't force cycles - it **detects** what the model autonomously decided and executes accordingly. The model generates continuously until it emits an action marker.

### Why This Matters

- **Natural interleaving**: Reasoning and actions flow together naturally, not artificially separated
- **Strategic planning**: Model can reason about the entire task before acting, maintain long-term plans
- **Flexible adaptation**: Model can change strategy mid-stream without being locked into cycles
- **Better context management**: Single stream maintains coherence better than fragmented cycles

---

## üß† Innovation #2: Autonomous Memory Folding (The Recovery Mechanism)

> **"This is the really new and awesome part"** - The sophisticated "Thought Folding" system that goes beyond standard ReAct loops and gives the agent a mechanism for self-correction and handling long, complex tasks.

### What is "Thought Folding"?

**Thought Folding** is a process the agent can trigger when:
- It gets stuck in loops
- Its reasoning history becomes too long
- It realizes its current approach isn't working
- It needs to change direction

Instead of continuing down a failing path, the agent **pauses, reflects on its entire interaction history, and compresses it into three distinct types of memory**. This summarized memory then guides its next attempt, effectively letting it **"reboot" its strategy with the wisdom of past failures**.

> In short, it mimics a human's ability to "take a step back, think about the problem, and try a new approach."

### The Problem It Solves

Long interaction histories cause:
- **Context bloat**: Token count explodes, degrading performance
- **Recovery difficulty**: Hard to escape failed exploration paths
- **Strategic drift**: Lose sight of long-term goals
- **Getting stuck in loops**: No built-in escape hatch

**Traditional solutions fail:**
- Simple truncation: Loses critical information
- Basic summarization: Suffers from "brevity bias" and "context collapse"
- Limited context windows: Can't compress long histories effectively
- Inefficient exploration: Doesn't learn from mistakes

### DeepAgent's Solution: Brain-Inspired Memory Architecture

When the model autonomously emits `<fold_thought>`, DeepAgent generates **three structured memory types in parallel**. The magic happens when the agent generates the `<fold_thought>` token - the system then calls `run_thought_folding` which uses an auxiliary LLM to create these structured memory components.

**1. Episode Memory** (`prompts_deepagent.py:414-450`)
- **Purpose**: "What happened?" - The agent's **long-term memory**
- **Metaphor**: Like the agent writing a **diary** of what it has tried, what worked, and what didn't
- **Function**: Summarizes the entire history into key milestones, decisions, and outcomes
- **Benefit**: Allows the agent to avoid repeating major mistakes
- **Structure**: 
  ```json
  {
    "task_description": "Overall goals",
    "key_events": [
      {"step": "1", "description": "Action taken", "outcome": "Result"},
      ...
    ],
    "current_progress": "What's done, what's left"
  }
  ```

**2. Working Memory** (`prompts_deepagent.py:453-488`)
- **Purpose**: "Where are we now?" - The agent's **short-term focus**
- **Metaphor**: Like a snapshot of the agent's immediate state
- **Function**: Extracts only the immediate goals, current challenges, and potential next steps
- **Benefit**: Helps the agent cut through the noise of a long history and concentrate on what's most important **right now**
- **Structure**:
  ```json
  {
    "immediate_goal": "Current subgoal",
    "current_challenges": "Main obstacles",
    "next_actions": [
      {"type": "tool_call/planning", "description": "Next step"}
    ]
  }
  ```

**3. Tool Memory** (`prompts_deepagent.py:490-538`)
- **Purpose**: "What works?" - A form of **skill acquisition**
- **Metaphor**: Like the agent learning from experience to become a better tool user
- **Function**: Reflects on how it has used its tools, learning about effective parameter combinations, common failure modes, and what kind of output to expect
- **Benefit**: Helps it become a more efficient tool user over time
- **Structure**:
  ```json
  {
    "tools_used": [
      {
        "tool_name": "...",
        "success_rate": 0.8,
        "effective_parameters": ["param1", "param2"],
        "common_errors": ["error_type"],
        "experience": "What we learned"
      }
    ],
    "derived_rules": [
      "When X, prefer tool Y",
      "Tool Z works best with param A=B"
    ]
  }
  ```

### Implementation Details

**Trigger** (`run_deep_agent.py:559-590`):
```python
# The main loop doesn't just look for tool calls, but specifically checks for the FOLD_THOUGHT token
elif seq['output'].rstrip().endswith(FOLD_THOUGHT):
    # Model autonomously decided to fold
    # This condition triggers the run_thought_folding function, which is the heart of the memory generation process
    episode_memory, working_memory, tool_memory = await run_thought_folding(...)
```

**Parallel Generation** (`run_deep_agent.py:292-384`):
```python
async def run_thought_folding(...):
    # Generate all three memories in parallel (efficiency!)
    episode_memory, working_memory, tool_memory = await asyncio.gather(
        generate_episode_memory(),
        generate_working_memory(),
        generate_tool_memory()
    )
    return episode_memory, working_memory, tool_memory
```

**Reset** (`run_deep_agent.py:580-581`):
```python
# Prepend memories to original prompt, reset token count
# The generated memory is then prepended to the prompt for the NEXT round of reasoning,
# giving the agent a clean slate but with a rich, summarized context
append_text = f"Memory of previous folded thoughts:\n\nEpisode Memory:\n{episode_memory}\n\nWorking Memory:\n{working_memory}\n\nTool Memory:\n{tool_memory}"
seq['prompt'] = seq['original_prompt'].replace("Now, begin your reasoning for", f"{append_text}\n\nNow, begin your reasoning for")
total_tokens = len(seq['prompt'].split())  # Reset token count - fresh start!
```

**Result**: Model starts fresh reasoning with distilled wisdom, avoiding context explosion while preserving strategic knowledge. The agent effectively **"reboots" its strategy** with the wisdom of past failures.

### Why This Is Brilliant

This "Thought Folding" system is a **significant step up from simple agent loops** because it directly addresses common failure points in AI agents:

- **Getting Stuck in Loops**: Provides a built-in escape hatch - the agent can fold and try a new approach
- **Limited Context Windows**: Compresses long histories into a dense, useful summary without losing critical information
- **Inefficient Exploration**: Learns from its mistakes and improves its strategy on the fly
- **Psychologically grounded**: Mirrors how humans manage complex tasks (episodic, working, procedural memory)
- **Targeted retrieval**: Can access "what happened" (episode), "where are we" (working), or "what works" (tool) separately
- **Parallel efficiency**: Three memories generated simultaneously, not sequentially
- **Strategic reset**: Enables recovery from failed paths, maintains long-horizon focus

**Key Insight**: The main reasoning prompts (e.g., `main_reasoning_prompt_closeset_general_qa`) explicitly instruct the model on **how and when** to use `<fold_thought>`. This is the **"operating system"** of the agent - the structured prompts enable the agent to perform such detailed and useful self-reflection.

---

## üîß Innovation #3: Multi-LLM Specialization (The Efficiency Hack)

### The Architecture

**Main Reasoning LLM** (e.g., QwQ-32B, Qwen3-Thinking)
- Focuses on: High-level reasoning, task planning, decision-making
- Handles: Tool searches, tool calls, memory folding decisions

**Auxiliary LLM** (e.g., Qwen2.5-Instruct, Qwen3-Instruct)
- Focuses on: Meta-tasks, context management, analysis
- Handles: Tool selection filtering, response analysis, memory generation

### Where It's Used

**1. Tool Selection** (`run_deep_agent.py:175-236`)
```python
async def run_tool_selection(...):
    # Use AUXILIARY LLM to filter/search tools
    helpful_tools = await generate_response(
        client=aux_client,  # NOT main client!
        model_name=args.aux_model_name,
        ...
    )
```

When tool search returns >15,000 characters, the auxiliary LLM filters down to most relevant tools. This prevents overwhelming the main reasoning model.

**2. Tool Response Analysis** (`run_deep_agent.py:238-289`)
```python
async def run_tool_response_analysis(...):
    # Use AUXILIARY LLM to summarize long tool responses
    if len(str(tool_response)) > 5000:
        tool_response = await generate_response(
            client=aux_client,  # NOT main client!
            ...
        )
```

Long tool responses (>5000 chars) are analyzed and summarized by the auxiliary LLM, keeping context manageable.

**3. Memory Generation** (`run_deep_agent.py:292-384`)
```python
async def run_thought_folding(...):
    # All three memory types generated by AUXILIARY LLM
    episode_memory, working_memory, tool_memory = await asyncio.gather(
        generate_episode_memory(client=aux_client, ...),
        generate_working_memory(client=aux_client, ...),
        generate_tool_memory(client=aux_client, ...)
    )
```

All memory generation uses the auxiliary LLM, freeing the main model to focus on reasoning.

### Why This Division of Labor Works

- **Cost efficiency**: Auxiliary model is typically smaller/faster, handles routine tasks
- **Focus**: Main model doesn't get distracted by context management
- **Parallelization**: Can generate multiple memories simultaneously
- **Scalability**: Can handle large tool sets and long responses without overwhelming main model

---

## üéØ Innovation #4: Intelligent Tool Management

### Dynamic Tool Discovery

**Tool Search Flow** (`run_deep_agent.py:445-492`):
1. Model emits `<tool_search>query</tool_search>`
2. System retrieves tools via semantic search (vector embeddings)
3. If results too large ‚Üí auxiliary LLM filters to most relevant
4. Tools added to `seq['available_tools']` (accumulated throughout task)
5. Results fed back to model for continued reasoning

**Key Feature**: Tools accumulate - once discovered, they remain available for the entire task.

### Smart Response Handling

**Long Response Summarization** (`run_deep_agent.py:516-526`):
```python
if len(str(tool_response)) > 5000:
    tool_response = await run_tool_response_analysis(
        client=aux_client,
        tool_call=adapted_tool_call,
        current_output=seq['output'],
        tool_response=tool_response,
    )
```

The auxiliary LLM analyzes tool responses and extracts only relevant information, preventing context bloat.

### Duplicate Prevention

```python
if tool_search_query in seq['executed_search_queries']:
    # Prevent redundant searches
    append_text = f"\n\n{BEGIN_TOOL_SEARCH_RESULT}You have already searched for this query.{END_TOOL_SEARCH_RESULT}\n\n"
```

Prevents wasted actions on duplicate searches/calls.

---

## üí° Innovation #5: Token-Aware Execution

### Smart Context Management

**Token Counting** (`run_deep_agent.py:400-401, 423-424, 589`):
```python
MAX_TOKENS = 40000
total_tokens = len(seq['prompt'].split())

# Track tokens throughout
tokens_this_response = len(response.split())
total_tokens += tokens_this_response

# Reset on memory fold
total_tokens = len(seq['prompt'].split())  # Fresh start
```

**Action Limits** (`run_deep_agent.py:443`):
```python
if seq['action_count'] < args.max_action_limit and total_tokens < MAX_TOKENS:
    # Continue reasoning
else:
    # Force final answer
```

System tracks both action count and token count, preventing runaway execution.

---

## üìç Where to Focus: Core Files

### Primary Files (Essential Reading)

1. **`src/run_deep_agent.py:387-645`** - `generate_main_reasoning_sequence()`
   - **THE CORE LOOP** - This is where everything happens
   - Unified reasoning with autonomous action dispatch
   - Memory folding trigger and reset logic
   - Token and action limit management

2. **`src/run_deep_agent.py:292-384`** - `run_thought_folding()`
   - Parallel generation of three memory types
   - Uses auxiliary LLM for memory generation

3. **`src/prompts/prompts_deepagent.py`** - All prompt definitions
   - `main_reasoning_prompt_openset_general_qa()` - Unified reasoning paradigm
   - `main_reasoning_prompt_closeset_general_qa()` - **The "operating system"** that instructs the model on how and when to use `<fold_thought>`
   - `get_episode_memory_instruction()` - Episode memory structure (agent's "diary")
   - `get_working_memory_instruction()` - Working memory structure (short-term focus)
   - `get_tool_memory_instruction()` - Tool memory structure (skill acquisition)

4. **`src/run_deep_agent.py:175-289`** - Tool intelligence functions
   - `run_tool_selection()` - Filtering retrieved tools
   - `run_tool_response_analysis()` - Summarizing long responses

### Supporting Files (Important Context)

5. **`src/tools/tool_manager.py`** - Tool execution abstraction
   - Handles different datasets (ToolBench, ALFWorld, WebShop, GAIA, etc.)
   - Unified interface for tool calling

6. **`src/tools/tool_search.py`** - Semantic tool retrieval
   - Vector embeddings for tool search
   - Uses sentence transformers (BGE, E5)

---

## üîç Key Code Patterns to Understand

### Pattern 1: Autonomous Action Detection
```python
# Model generates naturally, system detects markers
response = await generate_response(...)
tool_search_query = extract_between(response, BEGIN_TOOL_SEARCH, END_TOOL_SEARCH)
tool_call_query = extract_between(response, BEGIN_TOOL_CALL, END_TOOL_CALL)

# System executes what model decided
if tool_search_query:
    # Execute search
elif tool_call_query:
    # Execute call
```

### Pattern 2: Memory Folding Reset
```python
# Generate memories
memories = await run_thought_folding(...)

# Reset prompt with memories
seq['prompt'] = seq['original_prompt'].replace(
    "Now, begin your reasoning for",
    f"{memories}\n\nNow, begin your reasoning for"
)
total_tokens = len(seq['prompt'].split())  # Fresh start
```

### Pattern 3: Dual LLM Usage
```python
# Main model: reasoning
response = await generate_response(client=main_client, ...)

# Auxiliary model: meta-tasks
filtered_tools = await generate_response(client=aux_client, ...)
memory = await generate_response(client=aux_client, ...)
```

---

## üéì What Makes This Really New and Awesome

### 1. **Eliminates Phase Boundaries**
Unlike ReAct which forces Think-Act-Observe cycles, DeepAgent maintains one continuous reasoning stream. The model naturally interleaves reasoning with actions.

### 2. **Brain-Inspired Memory System**
The three-type memory (episodic, working, tool) mirrors human cognitive architecture. This provides richer semantics than flat summarization and enables targeted information retrieval.

### 3. **Autonomous Control**
The model itself decides when to act, search, or fold. No external meta-reasoner needed - control is embedded in the reasoning stream.

### 4. **Multi-LLM Efficiency**
Division of labor between main reasoning model and auxiliary model prevents context overload while maintaining efficiency.

### 5. **Recovery Mechanism**
Memory folding enables recovery from failed exploration paths and maintains strategic focus without context explosion.

---

## üöÄ Bottom Line

**The really awesome part**: DeepAgent replaces rigid agent workflows with **autonomous, unified reasoning** that naturally handles long-horizon tasks through intelligent memory management.

**The core innovation**: The **"Thought Folding" and structured memory management system** - this is what makes DeepAgent go beyond a standard ReAct loop and gives the agent sophisticated self-correction capabilities.

**Where to focus**: Start with `generate_main_reasoning_sequence()` in `run_deep_agent.py` - this is the heart of the system. Understand how it:
1. Detects autonomous action markers (`<tool_search>`, `<tool_call>`, `<fold_thought>`)
2. Executes actions and feeds results back
3. **Specifically checks for the `FOLD_THOUGHT` token** - this triggers the memory generation process
4. Resets with structured memories (episode, working, tool) - giving the agent a clean slate with rich context

**The magic is in the seamless integration** of reasoning, action, and memory management within a single coherent stream. The Thought Folding system enables the agent to:
- Escape from stuck loops
- Compress long histories without losing critical information
- Learn from mistakes and improve strategy on the fly
- Mimic human problem-solving: "take a step back, think about the problem, and try a new approach"

This is the **key agentic logic** in the system that is worth studying closely.

